{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 7. Practice Session II\n",
    "\n",
    "For the past two months, we have been trying to release python code on small problems and exercises. At the last seminars of this course, we invite you to expand the scope of your skills.\n",
    "\n",
    "Today, we're going to finish **political leaning prediction** exercise by constructing concrete predictions for survey respondents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "During the last week, we applied some data cleaning and EDA techniques to prepare our data. Sum up each step of this process into single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../turkey_political_opinions.csv\")\n",
    "# df_test = pd.read_csv(\"../turkey_political_opinions_test.csv\")\n",
    "\n",
    "df_train.columns[5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df, ques_name_list):\n",
    "\n",
    "    df1 = df.copy()\n",
    "\n",
    "    # replace values\n",
    "\n",
    "\n",
    "    # rename columns\n",
    "\n",
    "\n",
    "    # create voter Profile feature\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnemo = ['Econ_stat_good', 'Edu_reform', 'Privatisation', 'Death_penalty', 'Neut_journ', 'Alc_past_22_prohib', 'Secular_state', 'Abortion_ban', 'Ohal_freedom', 'New_parties']\n",
    "df_new = data_cleaning(df_train, mnemo)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions: what-if analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week you and I made different hypotheses and tested them with graphical and metric conclusions - thus confirming or refuting them. *(Actually, it's better to test hypotheses involving fractions or numbers using statistical tests-but you'll learn about that in another class)*. \n",
    "\n",
    "Today we'll look at the problem from a more practical point of view by fitting the tested hypotheses to the results of the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis 1: abortion ban\n",
    "\n",
    "**The right is more likely to vote to ban abortion than the left.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['h1'] = ['Right' if abor == \"Yes\" else \"Left\" for abor in df_new['Abortion_ban']]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your hypothesis could contain multiple rules, e.g.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis 2: äbortion ban and alco past 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = []\n",
    "for i, row in df_new.iterrows():\n",
    "    if row[10] == \"Yes\":\n",
    "        if row[12] == \"Yes\":\n",
    "            h2.append(\"Right\")\n",
    "        else:\n",
    "            h2.append(\"Left\")\n",
    "    else:\n",
    "        h2.append(\"Left\")\n",
    "\n",
    "df_new[\"h2\"] = h2\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that our hypothesis is correct, we can compare the distribution of actual and predicted variables. Confusion matrix is the tool to comare results of **binary classification**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_new['Profile'], df_new['h1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1400/1*fxiTNIgOyvAombPJx5KGeA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** is the most simple and well-known metric for classifications. To calculate it, we need to divide number of values predicted correctly by the whole number of values:\n",
    "\n",
    "*Accuracy =* $\\frac{TP + TN}{obs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy is:\", round((pd.crosstab(df_new['Profile'], df_new['h1'])['Left'][0] + pd.crosstab(df_new['Profile'], df_new['h1'])['Right'][1])/len(df_new),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the predictions on 2nd hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><font color='Pink'>***Your turn:***</font></u> \n",
    "\n",
    "Propose the hypothesis with the highest accuracy and calculate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions: simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X = pd.get_dummies(df_new.drop(columns = [\"Profile\", \"Timestamp\", \"h1\", \"Party\"]))\n",
    "y = df_new['Profile']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "y_pred = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred, target_names=['Left', 'Right']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(metrics.confusion_matrix(y, y_pred)), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "Text(0.5,257.44,'Predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check our model on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../turkey_political_opinions_test.csv\")\n",
    "df_test = data_cleaning(df_test, mnemo)\n",
    "df_test.loc[len(df_test.index)] = ['5/11/2018 9:59:47', 'Male', '60+', 'Güneydoğu', 'High School', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', \"DIĞER\", \"Right\"] \n",
    "\n",
    "y_test = df_test['Profile']\n",
    "X_test = pd.get_dummies(df_test.drop(columns = [\"Profile\", \"Timestamp\", \"Party\"]))\n",
    "y_pred_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(metrics.confusion_matrix(y_test, y_pred_test)), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "Text(0.5,257.44,'Predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final ~~Fantasy~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for attending the classes of this course. This was an amazing experience for me, and I hope that you had overcome barriers to learn programming languages. I know that the course was not the easiest one, but I tried to make it as understandable and interesting as is possible in terms of 8-week schedule. Remember: that's not always about boring coding, and you can solve a lot of social sciences problems with it.  \n",
    "\n",
    "If you will have any questions about Python, computational social science or qualitative methods, feel free to contact me any time via telegram `@alexpoov` or email `alexpoov99@gmail.com`.\n",
    "\n",
    "Good luck on your exams!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db967a82a5395c9886e36287b4fc3d4cdf41cf28b68e7cdaae12bdbf290d326d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
